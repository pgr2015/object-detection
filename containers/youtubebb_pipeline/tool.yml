entry_point: "bonseyes_containers.pipeline_api:create_pipeline_app"
run_function: "youtubebb_pipeline:execute_run"
description: "ObjectRecognition Task pipeline"
output_type: com.bonseyes.example.youtubebb.pipeline
parameters: {}
containers:
 youtubebb_pipeline:
  type: pipeline
 youtubebb_import:
  type: data
 youtubebb_export:
  type: data
 youtubebb_train_validation_split:
  type: data
 youtubebb_training:
  type: model 
task:
  name: com.bonseyes.examples.youtubebb
  description: |
    This task consists in recognizing objects. The input of the task is an RGB scale image containing
    exactly one scene. The objective is to detect which objects are represented in the image.
  output: |
    The task output is the number representing the object that has been recognized.
  constraints: |
    No constraints are defined.
  archives: |
    This task can be trained with the following archives:

      - http://bonseyes.uclm.es/BONSEYES_Reference_Datasets/YoutubeBB/training/imagesyoutubeBB_T.tar.gz
      - http://bonseyes.uclm.es/BONSEYES_Reference_Datasets/YoutubeBB/training/youtube_boundingboxes_detection_train.csv

    The archives format are .png images representing the labelled image frames of the YouTube Bounding Boxes
    data set and the labels have been modified following the input squeezeDet network format (KITTY label format)

  evaluation_criteria: |
    This task is evaluated using the accuracy metric. The accuracy is defined as the percentage of images for
    which the detected digit corresponds to the ground truth.

  cost_function: |
    The cost function that needs to be minimized is the categorical crossentropy.

  evaluation_dataset: |
    This task can be evaluated with the following archives:
    
      - http://bonseyes.uclm.es/BONSEYES_Reference_Datasets/SceneClassification/testSetPlaces205_resize.tar.gz
      - 

    The archives format is specified at http://data.csail.mit.edu/places/places205/

  visualization: visualization
